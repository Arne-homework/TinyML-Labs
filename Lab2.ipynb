{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzHYKcWEHTGu"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ds-kiel/TinyML-Labs/blob/WS24-25/Lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ds-kiel/TinyML-Labs/blob/WS24-25/Lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://raw.githubusercontent.com/ds-kiel/TinyML-Labs/WS24-25/Lab2.ipynb\" download><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdQ1KVS0HZXS"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Before starting, you must click on the \"Copy To Drive\" option in the top bar. Go to File --> Save a Copy to Drive. Name it *'Group\\<Your group number\\>_Lab2.ipynb'*. <ins>This is the master notebook so you will not be able to save your changes without copying it !</ins> Once you click on that, make sure you are working on that version of the notebook so that your work is saved.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "THIS IS A PRELIMINARY VERSION OF THE LAB! THE FINAL VERSION WILL FOLLOW BEFORE THE WEEKEND!\n",
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvrMU-DIHePo"
      },
      "source": [
        "# Lab 2: Quantization and On-Device Execution\n",
        "\n",
        "In the first lab you looked at the first part of the pipeline from data to executing models on low-power devices. You explored how to preprocess data and train neural networks with Edge Impulse. In this lab we continue the pipeline and you will explore how to [convert](https://ai.google.dev/edge/litert/models/convert_tf) a model to a [LiteRT](https://ai.google.dev/edge/litert) model, how to [quantize](https://ai.google.dev/edge/litert/models/post_training_integer_quant) [a model](https://www.tensorflow.org/model_optimization/guide/quantization/post_training), how to use [quantization-aware training](https://www.tensorflow.org/model_optimization/guide/quantization/training) and finally how to deploy the model and use the model with a microcontroller.\n",
        "\n",
        "You will explore the full pipeline from data to device using Tensorflow. You will train a model and convert, deploy, and execute it on a microcontroller, specifically the [Arduino Nano 33 BLE Sense](https://store.arduino.cc/products/arduino-tiny-machine-learning-kit).\n",
        "\n",
        "## Environment\n",
        "\n",
        "The instructions for this lab come as a [Jupyter Notebook](https://jupyter.org/). You can run it locally in your own Python environment, but we recommend you to use [Google Colab](https://colab.research.google.com) to save your computer hardware, have an instantly working python environment, and allow for easy collaboration. If your decide to use your local computer, take a look at Python virtual environments to avoid messing with your usual Python environment.\n",
        "\n",
        "Moreover, you need to obtain an API key from an Edge Impulse project. Register at [edgeimpulse.com](https://edgeimpulse.com/), log in and create a new project. Open the project, navigate to **Dashboard** and click on the **Keys** tab to view your API keys. Double-click on the API key to highlight it, right-click, and select **Copy**. Paste the key below in the cell starting with `ei.API_KEY`.\n",
        "\n",
        "![Copy API key from Edge Impulse project](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/python-sdk-copy-ei-api-key.png)\n",
        "\n",
        "For this lab you will not use the project in the Edge Impulse Studio. We just need the API Key.\n",
        "\n",
        "## What do you need to hand in?\n",
        "\n",
        "This Jupyter Notebook is intended as a document that you use both for working on the lab as well as for answering the questions. For handing in your lab, please **upload this Jupyter notebook**. Make sure that all images you include and outputs you generate are visible in the version you hand in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2d8yFY1GUX1"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOJvKcsUGWH1"
      },
      "outputs": [],
      "source": [
        "# If you have not done so already, install the following dependencies\n",
        "!python -m pip install tensorflow tensorflow-model-optimization scikit-learn edgeimpulse numpy matplotlib seaborn cbor2 pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTICd15rGZGx"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7yRUuJUGaq-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import cbor2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# from tensorflow.lite import TFLiteConverter\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import edgeimpulse as ei\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhIKkymAGfqu"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRxTHnJcGk0a"
      },
      "outputs": [],
      "source": [
        "plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "def plot_training_history(history, model_name):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle(f'Model {model_name}')\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "    ax1.plot(range(1, len(history.history['accuracy'])+1), history.history['accuracy'])\n",
        "    ax1.plot(range(1, len(history.history['val_accuracy'])+1), history.history['val_accuracy'])\n",
        "    ax1.set_title('Model accuracy')\n",
        "    ax1.set(xlabel='epoch', ylabel='accuracy')\n",
        "    ax1.legend(['training', 'validation'], loc='best')\n",
        "\n",
        "    ax2.plot(range(1, len(history.history['loss'])+1), history.history['loss'])\n",
        "    ax2.plot(range(1, len(history.history['val_loss'])+1), history.history['val_loss'])\n",
        "    ax2.set_title('Model loss')\n",
        "    ax2.set(xlabel='epoch', ylabel='loss')\n",
        "    ax2.legend(['training', 'validation'], loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62RGknKGGopG"
      },
      "source": [
        "### Edge Impulse API Key\n",
        "\n",
        "Insert your Edge Impulse API Key as in Lab 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERLWd1g2GzXd"
      },
      "outputs": [],
      "source": [
        "ei.API_KEY = \"ei_dae2...\" # Change this to your Edge Impulse API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9j7urCG-6E"
      },
      "source": [
        "## Edge Impulse Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZUVTQ2TIA10"
      },
      "source": [
        "### Prepare the data\n",
        "\n",
        "---\n",
        "**Task 1:** Navigate to the *Data acquisition* page in your Edge Impulse project of lab 1 and export the data.\n",
        "\n",
        "**Task 2:** Import the data with the code below.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = ['idle', 'circle', 'left-right', 'up-down'] # Change this to your labels\n",
        "num_classes = len(labels)\n",
        "\n",
        "data_path = '...' # Change this to the path of your downloaded folder\n",
        "\n",
        "# Select the window size and stride you used in Edge Impulse\n",
        "window_size_ms = 2000 \n",
        "window_stride_ms = 100\n",
        "\n",
        "\n",
        "# Function to create windows from the data\n",
        "def create_windows(df, window_size_ms, window_stride_ms, label):\n",
        "    window_size = int(window_size_ms / 10)\n",
        "    window_stride = int(window_stride_ms / 10)\n",
        "    windows = []\n",
        "    windows_labels = []\n",
        "    for i in range(0, len(df) - window_size, window_stride):\n",
        "        windows.append(df.iloc[i:i+window_size].values)\n",
        "        windows_labels.append(label)\n",
        "    return np.array(windows),windows_labels\n",
        "\n",
        "# Load the data from the files\n",
        "def load_data(data_path, folder):\n",
        "    data = np.zeros((1, int(window_size_ms / 10), 3))\n",
        "    data_labels = []\n",
        "    for file in os.listdir(data_path+folder):\n",
        "        if file.endswith('.cbor'):\n",
        "            label = file.split('.')[0].strip()\n",
        "            with open(data_path+folder+'/'+file, 'rb') as f_obj:\n",
        "                data_file = cbor2.load(f_obj)\n",
        "                df = pd.DataFrame(data_file['payload']['values'], columns=[item['name'] for item in data_file['payload']['sensors']])\n",
        "                df = df.drop(columns=['gyrX', 'gyrY', 'gyrZ', 'magX', 'magY', 'magZ'])\n",
        "\n",
        "                window_data, window_labels = create_windows(df, window_size_ms, window_stride_ms, labels.index(label))\n",
        "                data = np.concatenate((data, window_data), axis=0)\n",
        "                data_labels += window_labels\n",
        "\n",
        "    data = np.delete(data, 0, axis=0)\n",
        "    return data, data_labels\n",
        "\n",
        "\n",
        "x_train, y_train = load_data(data_path, 'training')\n",
        "x_test, y_test = load_data(data_path, 'testing')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Task 3 (optional):** Perform scaling on your data if you like to. *Please note: You have to do the same scaling later in your Arduino program.*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# perform your scaling here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt8W5N0UIHtY"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "---\n",
        "**Task 4:** Add your best model from lab 1, that uses a raw data preprocessing block.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWq43Tx6HxN1"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "def build_model(summary=True):\n",
        "    model = Sequential()\n",
        "\n",
        "    # ADD YOUR LAYERS HERE\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile model_mnist\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    if summary:\n",
        "        model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSs127krIdEc"
      },
      "outputs": [],
      "source": [
        "model = build_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1n_O2a6I0ee"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "So far, you manually explored how many epochs are necessary to successfully train the model. However, Tensorflow gives you an option to automate this called [early stopping](https://keras.io/api/callbacks/early_stopping/). See also [here](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/) and [here](https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd).\n",
        "\n",
        "---\n",
        "**Task 7:** Use an early stopping callback in your fitting function to find the optimal number of epochs. Use reasonable configurations. How many epochs does it train for?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCrSiGBcI2ot"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = EarlyStopping(\n",
        "    monitor=...,\n",
        "    patience=...,\n",
        "    min_delta=...,\n",
        "    mode=...\n",
        ")\n",
        "\n",
        "num_epochs = 200\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=num_epochs, validation_split=0.1, callbacks=[early_stopping_cb])\n",
        "plot_training_history(history, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_model = model.evaluate(x_test, y_test) #, verbose=0)\n",
        "print(\"Test loss:\", score_model[0])\n",
        "print(\"Test accuracy:\", score_model[1])\n",
        "\n",
        "cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(score_model.predict(x_test),axis=1))\n",
        "# print(cm)\n",
        "\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "cm = pd.DataFrame(cm, index = labels,\n",
        "                  columns = labels)\n",
        "\n",
        "plt.figure(figsize = (4,4))\n",
        "ax = sns.heatmap(cm*100,\n",
        "           annot=True,\n",
        "           fmt='.1f',\n",
        "           cmap=\"Blues\",\n",
        "           cbar=False,\n",
        "              )\n",
        "ax.set_ylabel(\"True Class\", fontdict= {'fontweight':'bold'})\n",
        "ax.set_xlabel(\"Predicted Class\", fontdict= {'fontweight':'bold'})\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Task 8:** How does the accuracy of your model compare to the accuracy you achieved with Edge Impulse?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### On-device resource consumption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After training your model, we want to know whether we can run it on a microcontroller or whether it is too large. We will use the [Edge Impulse Python SDK](https://docs.edgeimpulse.com/docs/tools/edge-impulse-python-sdk) for profiling, so if you didn't add your API key on top, now is the time.\n",
        "\n",
        "To start, we need to find the right target device for profiling. You are looking for the *Arduino Nano 33 BLE*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List the available profile target devices\n",
        "ei.model.list_profile_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next you can estimate the memory usage and inference time for each of your models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estimate the RAM, ROM, and inference time for our model on the target hardware family\n",
        "\n",
        "your_model = ...\n",
        "your_device = ...\n",
        "\n",
        "try:\n",
        "    profile = ei.model.profile(model=your_model,\n",
        "                               device=your_device)\n",
        "    print(profile.summary())\n",
        "except Exception as e:\n",
        "    print(f\"Could not profile: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Task 9:** Estimate the memory usage and inference time for your modes. **Compare your model's performance to your Edge Impulse models regarding ROM and RAM usage and their inference time**. Please do **<ins>not</ins>** use a table for this, but plot it, for example with [Matplotlib](https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_colors.html) or [Seaborn](https://seaborn.pydata.org/examples/grouped_barplot.html). Bar plots should be a good option for it. On the x-axis you can list the model and on the y-axis, you can show the respective memory usage for ROM and RAM.\n",
        "\n",
        "**Task 10:** Briefly explain your plot(s) of task 9.\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Model\n",
        "\n",
        "To come back to a model to continue working on it, it might be useful to save it. We can use the `model.save()` [Function](https://www.tensorflow.org/guide/keras/serialization_and_saving) that exports a TensorFlow model object to SavedModel format.\n",
        "\n",
        "If you use Google Colab, you can find the saved model as a `.keras`-file on the left under `Files/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "export_path = 'saved_model.keras'\n",
        "model.save(export_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Quantization\n",
        "\n",
        "Your microcontroller cannot use the Tensoflow model directly. Instead there is [LiteRT](https://ai.google.dev/edge/litert) for deploying models on mobile and edge devices.\n",
        "\n",
        "---\n",
        "**Task 11:** Load your model and convert it with LiteRT and save the model to a `.tflite`-file. (HINT: Check out [this](https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/examples/hello_world) *Hello World* example and [these instructions](https://ai.google.dev/edge/litert/models/convert_tf).)\n",
        "\n",
        "**Task 12:** Create a second LiteRT conversion that uses [optimizations](https://ai.google.dev/edge/api/tflite/python/tf/lite/Optimize) and enforce integer-only weights.\n",
        "(Maybe a helpful [resource](https://ai.google.dev/edge/litert/models/post_training_quantization).)\n",
        "\n",
        "**Task 13:** Create a third Tensorflow Lite conversion that in addition to the conversion in *Task 12* enforces integer-only quantization. (*Hint: Use a [representative dataset](https://ai.google.dev/edge/api/tflite/python/tf/lite/RepresentativeDataset).*)\n",
        "\n",
        "**Task 14:** Evaluate all three converted models and compare them to the Tensorflow model they are based on regarding profiled memory usage and accuracy. Use plots.\n",
        "\n",
        "**Task 15:** Explain your findings from Task 14. Why is there such a difference in performance and in memory usage?\n",
        "\n",
        "**Answer:** ...\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ADD YOUR MODEL CONVERSIONS HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the converted model\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quantization Aware Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Export - Library Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model conversion and library creation with Edge Impulse"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
